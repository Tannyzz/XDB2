{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "    https://www.youtube.com/watch?v=OGxgnH8y2NM\n",
    "    https://www.youtube.com/watch?v=JcI5Vnw0b2c#t=2.98320246\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pip3 install sklearn\n",
    "    pip3 install quandl\n",
    "    pip3 install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open    High     Low   Close      Volume  Ex-Dividend  \\\n",
      "Date                                                                  \n",
      "2004-08-19  100.00  104.06   95.96  100.34  44659000.0          0.0   \n",
      "2004-08-20  101.01  109.08  100.50  108.31  22834300.0          0.0   \n",
      "2004-08-23  110.75  113.48  109.05  109.40  18256100.0          0.0   \n",
      "2004-08-24  111.24  111.60  103.57  104.87  15247300.0          0.0   \n",
      "2004-08-25  104.96  108.00  103.88  106.00   9188600.0          0.0   \n",
      "\n",
      "            Split Ratio  Adj. Open  Adj. High  Adj. Low  Adj. Close  \\\n",
      "Date                                                                  \n",
      "2004-08-19          1.0     50.000      52.03    47.980      50.170   \n",
      "2004-08-20          1.0     50.505      54.54    50.250      54.155   \n",
      "2004-08-23          1.0     55.375      56.74    54.525      54.700   \n",
      "2004-08-24          1.0     55.620      55.80    51.785      52.435   \n",
      "2004-08-25          1.0     52.480      54.00    51.940      53.000   \n",
      "\n",
      "            Adj. Volume  \n",
      "Date                     \n",
      "2004-08-19   44659000.0  \n",
      "2004-08-20   22834300.0  \n",
      "2004-08-23   18256100.0  \n",
      "2004-08-24   15247300.0  \n",
      "2004-08-25    9188600.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import quandl\n",
    "df = quandl.get('WIKI/GOOGL')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "columnas == características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume\n",
      "Date                                                     \n",
      "2004-08-19      50.170  3.707395    0.340000   44659000.0\n",
      "2004-08-20      54.155  0.710922    7.227007   22834300.0\n",
      "2004-08-23      54.700  3.729433   -1.218962   18256100.0\n",
      "2004-08-24      52.435  6.417469   -5.726357   15247300.0\n",
      "2004-08-25      53.000  1.886792    0.990854    9188600.0\n"
     ]
    }
   ],
   "source": [
    "df = df[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]\n",
    "df['HL_PCT'] = (df['Adj. High'] - df['Adj. Close']) / df['Adj. Close'] * 100.0\n",
    "df['PCT_change'] = (df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open'] * 100.0\n",
    "df = df[['Adj. Close', 'HL_PCT', 'PCT_change', 'Adj. Volume']]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Características y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast_out = 30\n",
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume   label\n",
      "Date                                                             \n",
      "2004-08-19      50.170  3.707395    0.340000   44659000.0  66.290\n",
      "2004-08-20      54.155  0.710922    7.227007   22834300.0  67.530\n",
      "2004-08-23      54.700  3.729433   -1.218962   18256100.0  69.185\n",
      "2004-08-24      52.435  6.417469   -5.726357   15247300.0  68.540\n",
      "2004-08-25      53.000  1.886792    0.990854    9188600.0  69.425\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "forecast_col = 'Adj. Close'\n",
    "df.fillna(-99999, inplace=True)\n",
    "forecast_out = int(math.ceil(0.01*len(df)))  # desplazamiento hacia arriba\n",
    "print(\"forecast_out =\", forecast_out)\n",
    "df['label'] = df[forecast_col].shift(-forecast_out)\n",
    "df.dropna(inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(nota: se recompiló `numpy` con `easy_install --upgrade numpy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2932 2932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array(df.drop(['label'], 1))\n",
    "y = np.array(df['label'])\n",
    "X = preprocessing.scale(X)\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960745194098\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676831908822\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVR(kernel='poly')\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy) # no tan bueno!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.960745194098\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression(n_jobs=-1)  # tantos como aguante el procesador\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 762.23648159  759.57276181  766.8844566   764.59657194  762.01096211\n",
      "  759.64697089  758.26632401  770.0137785   771.63576156  767.50878702\n",
      "  774.08678168  769.44584431  763.33890722  772.8195701   764.17202393\n",
      "  764.01341722  761.59842633  769.37313119  776.3189003   779.94816142\n",
      "  784.80878598  792.12769485  779.2010205   779.55915176  784.35874612\n",
      "  737.91802424  746.56723447  727.7138098   725.91731826  706.41330142] 0.96265172885 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df.drop(['label'], 1))\n",
    "X = preprocessing.scale(X)\n",
    "X_lately  = X[-forecast_out:]\n",
    "X = X[:-forecast_out]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "y = np.array(df['label'])\n",
    "y = y[:-forecast_out]  # ajusta tamaño de y\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#pickle\n",
    "# Pickling and Scaling\n",
    "# pickling == serialización\n",
    "# objetivo: evitar entrenar el clasificador varias veces, se guarda en un archivo una vez\n",
    "# entrenado\n",
    "import pickle\n",
    "# aquí el clasificador ya está entrenado, así lo guardaremos\n",
    "\n",
    "with open(\"linearregression.pickle\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "pickle_in = open('linearregression.pickle', 'rb')\n",
    "clf = pickle.load(pickle_in)\n",
    "\n",
    "# fin de pickle  \n",
    "# una vez guardado, se puede omitir el código desde la linea clf = LinearRegression()\n",
    "# se puede crear el clasificador en equipos poderosos y recuperar el pickle en una\n",
    "# máquina mas pequeña para usarlo.\n",
    "\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "forecast_set = clf.predict(X_lately)\n",
    "print(forecast_set, accuracy, forecast_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import datetime\n",
    "\n",
    "style.use('ggplot')\n",
    "df['Forecast'] = np.nan\n",
    "\n",
    "#obtiene ultima fecha +1 \n",
    "last_date = df.iloc[-1].name\n",
    "last_unix = last_date.timestamp()\n",
    "one_day = 86400\n",
    "next_unix = last_unix + one_day\n",
    "\n",
    "for i in forecast_set:\n",
    "    next_date = datetime.datetime.fromtimestamp(next_unix)\n",
    "    next_unix += one_day\n",
    "    df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)] + [i]\n",
    "    \n",
    "df['Adj. Close'].plot()\n",
    "df['Forecast'].plot()\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teoría de regresión\n",
    "\n",
    "## regresión lineal\n",
    "\n",
    "y = mx+b\n",
    "\n",
    "m = ((x'y')-(xy)') / ( (x')^2 - (x^2)' )\n",
    "\n",
    "donde x' es la media de x (promedio)\n",
    "\n",
    "b = y' - m*(x')\n",
    "\n",
    "(ajuste a puntos que parecen formar una recta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/matplotlib/collections.py:571: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "xs = np.array([1,2,3,4,5,6], dtype=np.float64)\n",
    "ys = np.array([5,4,6,5,6,7], dtype=np.float64)\n",
    "\n",
    "#plt.scatter(xs, ys)\n",
    "#plt.show()\n",
    "\n",
    "def best_fit_slope_and_intercept(xs, ys):\n",
    "    m = ( (mean(xs) * mean(ys) - mean(xs * ys)) /\n",
    "         (mean(xs)**2 - mean(xs**2)) )\n",
    "    b = mean(ys) - m * mean(xs)\n",
    "    return m, b\n",
    "\n",
    "m, b = best_fit_slope_and_intercept(xs, ys)\n",
    "\n",
    "pred_x = 8\n",
    "pred_y = m * pred_x + b\n",
    "\n",
    "regression_line = [m*x+b for x in xs]\n",
    "plt.scatter(xs, ys)\n",
    "plt.scatter(pred_x, pred_y, color='g')\n",
    "\n",
    "plt.plot(xs, regression_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error (al cuadrado)\n",
    "\n",
    "r^2 = 1 - (SE y_fit)/ (SE y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.584415584416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/matplotlib/collections.py:571: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "xs = np.array([1,2,3,4,5,6], dtype=np.float64)\n",
    "ys = np.array([5,4,6,5,6,7], dtype=np.float64)\n",
    "\n",
    "#plt.scatter(xs, ys)\n",
    "#plt.show()\n",
    "\n",
    "def best_fit_slope_and_intercept(xs, ys):\n",
    "    m = ( (mean(xs) * mean(ys) - mean(xs * ys)) /\n",
    "         (mean(xs)**2 - mean(xs**2)) )\n",
    "    b = mean(ys) - m * mean(xs)\n",
    "    return m, b\n",
    "\n",
    "def squared_error(ys_orig, ys_line):  # SE\n",
    "    return sum((ys_line - ys_orig)**2)\n",
    "\n",
    "def coefficient_of_determination(ys_orig, ys_line):\n",
    "    y_mean_line = [mean(ys_orig)] * len(ys_orig)  # horizontal\n",
    "    squared_error_regr = squared_error(ys_orig, ys_line)\n",
    "    squared_error_y_mean = squared_error(ys_orig, y_mean_line)\n",
    "    return 1 - (squared_error_regr / squared_error_y_mean)\n",
    "\n",
    "m, b = best_fit_slope_and_intercept(xs, ys)\n",
    "\n",
    "# predictions\n",
    "pred_x = 8\n",
    "pred_y = m * pred_x + b\n",
    "\n",
    "# squared error\n",
    "r_squared = coefficient_of_determination(ys, regression_line)\n",
    "print(r_squared)\n",
    "\n",
    "regression_line = [m*x+b for x in xs]\n",
    "plt.scatter(xs, ys)\n",
    "plt.scatter(pred_x, pred_y, color='g')\n",
    "\n",
    "plt.plot(xs, regression_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datos de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00366506658335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/matplotlib/collections.py:571: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import random\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "#xs = np.array([1,2,3,4,5,6], dtype=np.float64)\n",
    "#ys = np.array([5,4,6,5,6,7], dtype=np.float64)\n",
    "\n",
    "#plt.scatter(xs, ys)\n",
    "#plt.show()\n",
    "\n",
    "def best_fit_slope_and_intercept(xs, ys):\n",
    "    m = ( (mean(xs) * mean(ys) - mean(xs * ys)) /\n",
    "         (mean(xs)**2 - mean(xs**2)) )\n",
    "    b = mean(ys) - m * mean(xs)\n",
    "    return m, b\n",
    "\n",
    "def squared_error(ys_orig, ys_line):  # SE\n",
    "    return sum((ys_line - ys_orig)**2)\n",
    "\n",
    "def coefficient_of_determination(ys_orig, ys_line):\n",
    "    y_mean_line = [mean(ys_orig)] * len(ys_orig)  # horizontal\n",
    "    squared_error_regr = squared_error(ys_orig, ys_line)\n",
    "    squared_error_y_mean = squared_error(ys_orig, y_mean_line)\n",
    "    return 1 - (squared_error_regr / squared_error_y_mean)\n",
    "\n",
    "def create_dataset(hm, variance, step=2, correlation=False):\n",
    "    val = 1\n",
    "    ys = []\n",
    "    for i in range(hm):\n",
    "        y = val + random.randrange(-variance, variance)\n",
    "        ys.append(y)\n",
    "        if correlation and correlation == 'pos':\n",
    "            val += step\n",
    "        elif correlation and correlation == 'neg':\n",
    "            val -= step\n",
    "    xs = range(hm)\n",
    "    return np.array(xs, dtype=np.float64), np.array(ys, dtype=np.float64)\n",
    "\n",
    "xs, ys = create_dataset(40, 10, 2, False)\n",
    "\n",
    "m, b = best_fit_slope_and_intercept(xs, ys)\n",
    "\n",
    "# predictions\n",
    "pred_x = xs[-1] + 1\n",
    "pred_y = m * pred_x + b\n",
    "\n",
    "regression_line = [m*x+b for x in xs]\n",
    "\n",
    "# squared error\n",
    "r_squared = coefficient_of_determination(ys, regression_line)\n",
    "print(r_squared)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.scatter(pred_x, pred_y, s=100, color='g')\n",
    "\n",
    "plt.plot(xs, regression_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import quandl, math, datetime\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import matplotlib as mpl\n",
    "\n",
    "style.use('ggplot')\n",
    "mpl.rcParams['lines.linewidth'] = 0.5\n",
    "\n",
    "df = quandl.get('WIKI/GOOGL')\n",
    "df = df[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]\n",
    "df['HL_PCT'] = (df['Adj. High'] - df['Adj. Close']) / df['Adj. Close'] * 100.0\n",
    "df['PCT_change'] = (df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open'] * 100.0\n",
    "\n",
    "\n",
    "df = df[['Adj. Close', 'HL_PCT', 'PCT_change', 'Adj. Volume']]\n",
    "\n",
    "forecast_col = 'Adj. Close'\n",
    "df.fillna(-99999, inplace=True)\n",
    "forecast_out = int(math.ceil(0.1*len(df)))  # desplazamiento hacia arriba\n",
    "df['label'] = df[forecast_col].shift(-forecast_out)\n",
    "\n",
    "X = np.array(df.drop(['label'], 1))\n",
    "X = preprocessing.scale(X)\n",
    "X_lately  = X[-forecast_out:]\n",
    "X = X[:-forecast_out]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "y = np.array(df['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "forecast_set = clf.predict(X_lately)\n",
    "\n",
    "df['Forecast'] = np.nan\n",
    "\n",
    "#obtiene ultima fecha +1 \n",
    "last_date = df.iloc[-1].name\n",
    "last_unix = last_date.timestamp()\n",
    "one_day = 86400\n",
    "next_unix = last_unix + one_day\n",
    "\n",
    "for i in forecast_set:\n",
    "    next_date = datetime.datetime.fromtimestamp(next_unix)\n",
    "    next_unix += one_day\n",
    "    df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)] + [i]\n",
    "    \n",
    "df['Adj. Close'].plot()\n",
    "df['Forecast'].plot()\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clasificación por medio de los k - vecinos cercanos\n",
    "\n",
    "Obtiene los k vecinos más cercanos al punto a clasificar desde los datos, el punto se clasificará con la clase que tenga la mayoría de estos k-vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971428571429\n",
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, neighbors\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data.txt')\n",
    "df.replace('?', -99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "\n",
    "X = np.array(df.drop(['class'], 1))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier()  # default k=5\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "example_measures = np.array([[4,2,1,1,1,2,3,2,1], [4,2,1,2,4,2,3,2,1]])\n",
    "example_measures = example_measures.reshape(len(example_measures),-1)\n",
    "\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funcionamiento interno de k-vecinos cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/matplotlib/collections.py:571: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]}\n",
    "new_features = [5,7]\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than the total voting groups!')\n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)- np.array(predict))\n",
    "            distances.append([euclidean_distance, group])\n",
    "    votes = [i[1] for i in sorted(distances)[:k]] #ordena y toma los primeros k votos\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    \n",
    "    return vote_result\n",
    "\n",
    "result = k_nearest_neighbors(dataset, new_features, k=3)\n",
    "print(result)\n",
    "\n",
    "[[plt.scatter(*ii, s=100, color=i) for ii in dataset[i]] for i in dataset]\n",
    "plt.scatter(*new_features, color=result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Práctica con datos reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9856115107913669\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from matplotlib import style\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]}\n",
    "new_features = [5,7]\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than the total voting groups!')\n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)- np.array(predict))\n",
    "            distances.append([euclidean_distance, group])\n",
    "    votes = [i[1] for i in sorted(distances)[:k]] #ordena y toma los primeros k votos\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    \n",
    "    return vote_result\n",
    "\n",
    "df = pd.read_csv(\"breast-cancer-wisconsin.data.txt\")\n",
    "df.replace('?', -99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "full_data = df.astype(float).values.tolist()  #convierte datos a floats\n",
    "random.shuffle(full_data)\n",
    "\n",
    "\n",
    "\n",
    "test_size = 0.2  #  %\n",
    "train_set = {2:[], 4:[]}\n",
    "test_set = {2:[], 4:[]}\n",
    "train_data = full_data[:-int(test_size*len(full_data))]  # datos sin el último 20%\n",
    "test_data = full_data[-int(test_size*len(full_data)):]  # datos en el último 20%\n",
    "\n",
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "\n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1])\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote = k_nearest_neighbors(train_set, data, k=5)\n",
    "        if group == vote:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
